"""Table Multi-Vector Retriever for enhanced table search and retrieval."""

import uuid
from typing import List, Dict, Any, Optional, Tuple
import json
import re

from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun
from langchain_core.vectorstores import VectorStore
from langchain_core.language_models import BaseLLM
from langchain_classic.storage import InMemoryStore
from langchain_classic.storage.kvstore import create_kv_docstore
from langchain_classic.retrievers.multi_vector import MultiVectorRetriever

from app.core.logging import get_logger
from app.utils.table_validator import TableValidator, TableStructure

logger = get_logger(__name__)


class TableMultiVectorRetriever(BaseRetriever):
    """Multi-vector retriever optimized for table content.
    
    This retriever stores tables in multiple representations:
    1. Original table (markdown/HTML)
    2. Table summary (generated by LLM)
    3. Row-based chunks (for detailed search)
    4. Column descriptions (for schema search)
    """
    
    def __init__(
        self,
        vectorstore: VectorStore,
        llm: Optional[BaseLLM] = None,
        docstore: Optional[Any] = None,
        id_key: str = "doc_id",
        namespace: str = "tables"
    ):
        """Initialize table multi-vector retriever.
        
        Args:
            vectorstore: Vector store for embeddings
            llm: Language model for generating summaries
            docstore: Document store for full tables
            id_key: Key for document IDs
            namespace: Namespace for table documents
        """
        super().__init__()
        self.vectorstore = vectorstore
        self.llm = llm
        self.docstore = docstore or InMemoryStore()
        self.id_key = id_key
        self.namespace = namespace
        self.table_validator = TableValidator()
        
        # Create base multi-vector retriever
        self.base_retriever = MultiVectorRetriever(
            vectorstore=vectorstore,
            docstore=self.docstore,
            id_key=id_key
        )
        
    async def add_tables(self, table_documents: List[Document]) -> List[str]:
        """Add tables with multiple representations.
        
        Args:
            table_documents: Documents containing table content
            
        Returns:
            List of document IDs
        """
        all_docs_to_index = []
        doc_ids = []
        
        for table_doc in table_documents:
            try:
                # Generate unique ID for this table
                table_id = str(uuid.uuid4())
                doc_ids.append(table_id)
                
                # Extract and validate table structure
                table_structure = self._extract_table_structure(table_doc)
                
                if not table_structure:
                    logger.warning(f"Could not extract valid table structure from document")
                    continue
                
                # 1. Store original table
                self.docstore.mset([(table_id, table_doc)])
                
                # 2. Generate table summary
                if self.llm:
                    summary_doc = await self._generate_table_summary(table_doc, table_structure)
                    summary_doc.metadata[self.id_key] = table_id
                    all_docs_to_index.append(summary_doc)
                
                # 3. Create row-based chunks
                row_docs = self._create_row_chunks(table_doc, table_structure, table_id)
                all_docs_to_index.extend(row_docs)
                
                # 4. Create column descriptions
                col_docs = self._create_column_descriptions(table_doc, table_structure, table_id)
                all_docs_to_index.extend(col_docs)
                
                # 5. Create searchable representation of full table
                full_table_doc = self._create_searchable_table(table_doc, table_structure, table_id)
                all_docs_to_index.append(full_table_doc)
                
            except Exception as e:
                logger.error(f"Failed to process table: {e}")
                continue
        
        # Add all representations to vector store
        if all_docs_to_index:
            await self._add_documents_to_vectorstore(all_docs_to_index)
            
        logger.info(f"Added {len(doc_ids)} tables with {len(all_docs_to_index)} total representations")
        return doc_ids
        
    def _extract_table_structure(self, table_doc: Document) -> Optional[TableStructure]:
        """Extract and validate table structure."""
        content = table_doc.page_content
        metadata = table_doc.metadata
        
        # Check content type
        content_type = metadata.get("content_type", "")
        
        if content_type == "table_markdown":
            # Parse markdown table
            return self._parse_markdown_table(content)
        elif content_type == "table_html":
            # Parse HTML table
            return self._parse_html_table(content)
        elif content_type == "table_json":
            # Parse JSON table
            return self._parse_json_table(content)
        else:
            # Try to auto-detect
            if "|" in content and content.count("|") > 2:
                return self._parse_markdown_table(content)
            elif "<table" in content.lower():
                return self._parse_html_table(content)
                
        return None
        
    def _parse_markdown_table(self, content: str) -> Optional[TableStructure]:
        """Parse markdown table into structure."""
        lines = content.strip().split('\n')
        rows = []
        
        for line in lines:
            # Skip separator lines
            if re.match(r'^[\|\s\-:]+$', line):
                continue
            # Extract cells
            cells = [cell.strip() for cell in line.split('|') if cell.strip()]
            if cells:
                rows.append(cells)
                
        if rows:
            return self.table_validator.validate_table_structure(rows)
        return None
        
    def _parse_html_table(self, content: str) -> Optional[TableStructure]:
        """Parse HTML table into structure."""
        # This would use BeautifulSoup in production
        # For now, simple regex extraction
        rows = []
        
        # Extract table rows
        row_pattern = r'<tr[^>]*>(.*?)</tr>'
        cell_pattern = r'<t[hd][^>]*>(.*?)</t[hd]>'
        
        for row_match in re.finditer(row_pattern, content, re.DOTALL):
            row_content = row_match.group(1)
            cells = []
            for cell_match in re.finditer(cell_pattern, row_content, re.DOTALL):
                cell_text = re.sub(r'<[^>]+>', '', cell_match.group(1)).strip()
                cells.append(cell_text)
            if cells:
                rows.append(cells)
                
        if rows:
            return self.table_validator.validate_table_structure(rows)
        return None
        
    def _parse_json_table(self, content: str) -> Optional[TableStructure]:
        """Parse JSON table into structure."""
        try:
            data = json.loads(content)
            if isinstance(data, list) and data:
                # Convert list of dicts to table
                headers = list(data[0].keys())
                rows = [headers]
                for item in data:
                    row = [str(item.get(h, '')) for h in headers]
                    rows.append(row)
                return self.table_validator.validate_table_structure(rows)
        except json.JSONDecodeError:
            logger.warning("Failed to parse JSON table")
        return None
        
    async def _generate_table_summary(
        self, 
        table_doc: Document, 
        table_structure: TableStructure
    ) -> Document:
        """Generate LLM-based summary of table content."""
        if not self.llm:
            # Fallback to basic summary
            return self._create_basic_summary(table_doc, table_structure)
            
        # Create prompt for table summarization
        prompt = f"""Summarize this table concisely:

Title: {table_structure.title or 'Untitled Table'}
Headers: {', '.join(table_structure.headers)}
Row Count: {table_structure.row_count}
Column Count: {table_structure.column_count}

First few rows:
{table_structure.to_markdown(max_rows=5)}

Provide a brief summary of what this table contains and its key information."""

        try:
            summary = await self.llm.ainvoke(prompt)
            summary_text = summary.content if hasattr(summary, 'content') else str(summary)
        except Exception as e:
            logger.warning(f"LLM summary generation failed: {e}")
            return self._create_basic_summary(table_doc, table_structure)
            
        return Document(
            page_content=summary_text,
            metadata={
                **table_doc.metadata,
                "representation_type": "summary",
                "table_title": table_structure.title,
                "row_count": table_structure.row_count,
                "column_count": table_structure.column_count
            }
        )
        
    def _create_basic_summary(
        self, 
        table_doc: Document, 
        table_structure: TableStructure
    ) -> Document:
        """Create basic summary without LLM."""
        summary = f"Table: {table_structure.title or 'Data Table'}\n"
        summary += f"Contains {table_structure.row_count} rows and {table_structure.column_count} columns.\n"
        summary += f"Columns: {', '.join(table_structure.headers)}\n"
        
        if table_structure.summary:
            summary += f"\nSummary: {table_structure.summary}"
            
        return Document(
            page_content=summary,
            metadata={
                **table_doc.metadata,
                "representation_type": "summary"
            }
        )
        
    def _create_row_chunks(
        self, 
        table_doc: Document, 
        table_structure: TableStructure,
        table_id: str
    ) -> List[Document]:
        """Create searchable chunks for each row."""
        row_docs = []
        
        for i, row in enumerate(table_structure.data_rows):
            # Create key-value representation of row
            row_content = f"Row {i+1} from table '{table_structure.title or 'Data Table'}':\n"
            
            for j, (header, value) in enumerate(zip(table_structure.headers, row)):
                row_content += f"{header}: {value}\n"
                
            row_doc = Document(
                page_content=row_content,
                metadata={
                    **table_doc.metadata,
                    self.id_key: table_id,
                    "representation_type": "row",
                    "row_index": i,
                    "table_title": table_structure.title
                }
            )
            row_docs.append(row_doc)
            
        return row_docs
        
    def _create_column_descriptions(
        self, 
        table_doc: Document, 
        table_structure: TableStructure,
        table_id: str
    ) -> List[Document]:
        """Create descriptions for each column."""
        col_docs = []
        
        for i, header in enumerate(table_structure.headers):
            # Extract column data
            column_values = [row[i] for row in table_structure.data_rows if i < len(row)]
            
            # Create column description
            col_content = f"Column '{header}' from table '{table_structure.title or 'Data Table'}':\n"
            col_content += f"Contains {len(column_values)} values.\n"
            
            # Add sample values
            unique_values = list(set(column_values))[:10]  # First 10 unique values
            if unique_values:
                col_content += f"Sample values: {', '.join(str(v) for v in unique_values)}\n"
                
            # Detect data type
            data_type = self._detect_column_type(column_values)
            col_content += f"Data type: {data_type}\n"
            
            col_doc = Document(
                page_content=col_content,
                metadata={
                    **table_doc.metadata,
                    self.id_key: table_id,
                    "representation_type": "column",
                    "column_index": i,
                    "column_name": header,
                    "data_type": data_type
                }
            )
            col_docs.append(col_doc)
            
        return col_docs
        
    def _create_searchable_table(
        self, 
        table_doc: Document, 
        table_structure: TableStructure,
        table_id: str
    ) -> Document:
        """Create a searchable text representation of the full table."""
        content = f"Table: {table_structure.title or 'Data Table'}\n\n"
        
        # Add summary if available
        if table_structure.summary:
            content += f"Summary: {table_structure.summary}\n\n"
            
        # Add structured content
        content += "Table Content:\n"
        content += table_structure.to_markdown(max_rows=50)  # Limit for search
        
        return Document(
            page_content=content,
            metadata={
                **table_doc.metadata,
                self.id_key: table_id,
                "representation_type": "full_table",
                "row_count": table_structure.row_count,
                "column_count": table_structure.column_count
            }
        )
        
    def _detect_column_type(self, values: List[Any]) -> str:
        """Detect the predominant data type in a column."""
        if not values:
            return "empty"
            
        # Count types
        type_counts = {"numeric": 0, "date": 0, "text": 0, "boolean": 0}
        
        for value in values:
            value_str = str(value).strip()
            
            # Check numeric
            if re.match(r'^-?\d+\.?\d*$', value_str):
                type_counts["numeric"] += 1
            # Check date patterns
            elif re.match(r'\d{4}-\d{2}-\d{2}', value_str) or re.match(r'\d{2}/\d{2}/\d{4}', value_str):
                type_counts["date"] += 1
            # Check boolean
            elif value_str.lower() in ['true', 'false', 'yes', 'no', '0', '1']:
                type_counts["boolean"] += 1
            else:
                type_counts["text"] += 1
                
        # Return predominant type
        return max(type_counts, key=type_counts.get)
        
    async def _add_documents_to_vectorstore(self, documents: List[Document]) -> None:
        """Add documents to vector store in batches."""
        batch_size = 50
        
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            try:
                await self.vectorstore.aadd_documents(batch)
            except AttributeError:
                # Fallback to sync method
                self.vectorstore.add_documents(batch)
                
    def _get_relevant_documents(
        self,
        query: str,
        *,
        run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """Get relevant documents synchronously."""
        # Use base retriever for sync retrieval
        return self.base_retriever.get_relevant_documents(
            query, callbacks=run_manager.get_child()
        )
        
    async def _aget_relevant_documents(
        self,
        query: str,
        *,
        run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """Get relevant documents asynchronously.
        
        This method searches across all table representations and returns
        the original full tables for the most relevant matches.
        """
        # Search across all representations
        relevant_docs = await self.base_retriever.aget_relevant_documents(
            query, callbacks=run_manager.get_child()
        )
        
        # Group by table ID and aggregate scores
        table_scores: Dict[str, float] = {}
        table_docs: Dict[str, Document] = {}
        
        for doc in relevant_docs:
            table_id = doc.metadata.get(self.id_key)
            if not table_id:
                continue
                
            # Aggregate relevance scores
            score = doc.metadata.get("score", 1.0)
            rep_type = doc.metadata.get("representation_type", "unknown")
            
            # Weight scores by representation type
            weight_map = {
                "summary": 2.0,      # Summaries are highly relevant
                "full_table": 1.5,   # Full table matches are good
                "row": 1.0,          # Individual rows are specific
                "column": 0.8        # Column descriptions are less specific
            }
            weighted_score = score * weight_map.get(rep_type, 1.0)
            
            if table_id in table_scores:
                table_scores[table_id] += weighted_score
            else:
                table_scores[table_id] = weighted_score
                # Retrieve original table document
                original_docs = self.docstore.mget([table_id])
                if original_docs and original_docs[0]:
                    table_docs[table_id] = original_docs[0]
                    
        # Sort by aggregated score and return top tables
        sorted_tables = sorted(table_scores.items(), key=lambda x: x[1], reverse=True)
        
        result_docs = []
        for table_id, score in sorted_tables[:5]:  # Return top 5 tables
            if table_id in table_docs:
                doc = table_docs[table_id]
                doc.metadata["aggregated_score"] = score
                doc.metadata["retrieval_type"] = "multi_vector_table"
                result_docs.append(doc)
                
        return result_docs
